{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b1a2f8-2422-47a8-b3e2-eee2cacc5746",
   "metadata": {},
   "source": [
    "# Read files for the Mallee Woodlands\n",
    "\n",
    "This Excel workbook was prepared by Prof. David Keith, FAA, and imported on May 2023.\n",
    "\n",
    "We need to adapt functions defined in modules `fireveg` and `firevegdb`  to:\n",
    "\n",
    "- Read data from spreadsheets with field-work data\n",
    "- Create records for data import into the database\n",
    "- Insert or update records in the database\n",
    "\n",
    "For this dataset we have several sites (S2007/1, T2001/1, etc), each site has several subplots with different treatments (A, K, N, R, G, X1, X2, X3) and replicates for each site/subplot.\n",
    "\n",
    "This jupyter notebook runs through each step of data import, starting with field site and visit information. Then... other steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a04fac-d940-49e8-90cc-55b8a660f316",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set-up\n",
    "Load libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "049c8f14-e17d-4188-98c8-4477d94d8ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "from configparser import ConfigParser\n",
    "import psycopg2\n",
    "from psycopg2.extensions import AsIs\n",
    "import pyprojroot\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee583770-35a6-417b-afcb-37d5900f2ebe",
   "metadata": {},
   "source": [
    "Load functions from `lib` folder, we will use a function to read db credentials and one for batch insert and updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0132f0e1-6843-4ee3-b408-50de87e7324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.parseparams import read_dbparams\n",
    "from lib.firevegdb import batch_upsert\n",
    "from lib.firevegdb import validate_and_update_site_records\n",
    "\n",
    "import lib.fireveg as fv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68a87e-0fb6-4976-b0ba-0ab115de571d",
   "metadata": {},
   "source": [
    "Define path to workbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f70501e6-fbdf-4aae-a67f-b9fd30b75dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "repodir = pyprojroot.find_root(pyprojroot.has_dir(\".git\"))\n",
    "inputdir = repodir / \"data\" / \"input-field-form\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333fb8b-20ee-41ec-9be0-a9726356bdc3",
   "metadata": {},
   "source": [
    "Database credentials are stored in a database.ini file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51adc750-4ff8-4797-8d41-3ef8bc485a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbparams = read_dbparams(repodir / 'secrets' / 'database.ini', section='aws-lght-sl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b16d9-5538-43b0-b0f2-c8e0c4199575",
   "metadata": {
    "tags": []
   },
   "source": [
    "## List of workbooks/spreadsheets in directory\n",
    "\n",
    "Each spreadsheet has a slightly different structure, so these scripts have to be adapted for each case.\n",
    "\n",
    "We use functions from module `fireveg` to read the data and create records, and functions from module `firevegdb` to execute the SQL insert or update query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "729cc97e-b551-4059-9710-61b5a53cfcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton_revisedfields_Mar2022.xlsx',\n",
       " 'UNSW_VegFireResponse_KNP AlpAsh_firehistupdate.xlsx',\n",
       " 'SthnNSWRF_data_bionet2.xlsx',\n",
       " 'UNSWFireVegResponse_UplandBasalt_AlexThomsen+DK.xlsx',\n",
       " 'PlantFireTraitData_2011-2018_Import.xlsx',\n",
       " 'UNSW_VegFireResponse_RMK_reformat_Sep2021a.xlsx',\n",
       " 'UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton.xlsx',\n",
       " 'UNSW_VegFireResponse_KNP AlpAsh.xlsx',\n",
       " 'UNSW_VegFireResponse_AlpineBogs_reformat_Sep2021.xlsx',\n",
       " 'RobertsonRF_data_bionet2.xlsx',\n",
       " 'Fire response quadrat survey Newnes Nov2020_DK_revised IDs+AllNovData.xlsm']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(inputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6f7f38c-4f11-4054-b2f2-8e1309b3a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =  'PlantFireTraitData_2011-2018_Import.xlsx'\n",
    "valid_files = [filename]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42a0a2-9cd1-46a1-abcb-a5abb63b9584",
   "metadata": {},
   "source": [
    "Here we create an index of worksheets and column headers for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "629a0965-eae1-46fc-b49c-c858e6161b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbindex=dict()\n",
    "for workbook_name in valid_files:\n",
    "    inputfile=inputdir / workbook_name\n",
    "    # using data_only=True to get the calculated cell values\n",
    "    wb = openpyxl.load_workbook(inputfile,data_only=True)\n",
    "    wbindex[workbook_name]=dict()\n",
    "    for ws in wb.worksheets:\n",
    "        wbindex[workbook_name][ws._WorkbookChild__title]=list()\n",
    "        for k in range(1,ws.max_column):\n",
    "            wbindex[workbook_name][ws._WorkbookChild__title].append(ws.cell(row=1,column=k).value)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741e415-b034-4d81-ba5e-8e9d10b5d814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Database queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c336797-28e5-49d0-a3b3-8717acbbbb28",
   "metadata": {},
   "source": [
    "Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68b6db1e-51ab-49cf-9f97-c4a9bf12df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n"
     ]
    }
   ],
   "source": [
    "# connect to the PostgreSQL server\n",
    "print('Connecting to the PostgreSQL database...')\n",
    "conn = psycopg2.connect(**dbparams)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0245c2-fdfe-473f-955f-d34099e29788",
   "metadata": {},
   "source": [
    "### create new survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19eabe83-14d7-40af-91c4-9720aefd5958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO form.surveys(survey_name) values ('Mallee Woodlands') ON CONFLICT DO NOTHING;\n",
      "0 rows updated\n"
     ]
    }
   ],
   "source": [
    "updated_rows = 0\n",
    "qry = \"INSERT INTO form.surveys(survey_name) values ('Mallee Woodlands') ON CONFLICT DO NOTHING;\"\n",
    "cur.execute(qry)\n",
    "if cur.rowcount > 0:\n",
    "    updated_rows = cur.rowcount\n",
    "else:\n",
    "    print(qry)\n",
    "conn.commit() \n",
    "print(\"%s rows updated\" % (updated_rows))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d2f31cc-bf34-4b7b-b108-815fba90b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM form.surveys;\")\n",
    "surveys = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3344f30-f840-4771-bb9c-6ae7c389d9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TO BE CLASSIFIED',\n",
       "  'Placeholder for field visits not yet assigned to a survey',\n",
       "  'JR Ferrer-Paris'),\n",
       " ('NEWNES', 'NEWNES', None),\n",
       " ('KNP AlpAsh', 'Alpine Ash', None),\n",
       " ('UplandBasalt', 'Upland Basalt', None),\n",
       " ('Alpine Bogs', None, None),\n",
       " ('Robertson RF', None, None),\n",
       " ('Yatteyattah', None, None),\n",
       " ('SthnNSWRF', None, None),\n",
       " ('Rainforests NSW-Qld', 'Rainforests NE NSW & SE Qld', None),\n",
       " ('Mallee Woodlands', None, None)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ba5e1-8d6c-4760-9877-88267d4e8fca",
   "metadata": {},
   "source": [
    "### Valid vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25079d27-9d60-4935-82d3-a14b3b3dd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT enumlabel FROM pg_enum e LEFT JOIN pg_type t ON e.enumtypid=t.oid where typname='resprout_organ_vocabulary';\")\n",
    "valid_organ_list = cur.fetchall()\n",
    "organ_vocab = [item for t in valid_organ_list for item in t]\n",
    "\n",
    "cur.execute(\"SELECT enumlabel FROM pg_enum e LEFT JOIN pg_type t ON e.enumtypid=t.oid where typname='seedbank_vocabulary';\")\n",
    "valid_seedbank_list = cur.fetchall()\n",
    "seedbank_vocab = [item for t in valid_seedbank_list for item in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556673f3-c13d-4cda-9b8c-d846342d5057",
   "metadata": {},
   "source": [
    "### Close DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0dc80c9-9874-4b6f-912f-4b168ddb7847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "cur.close()\n",
    "if conn is not None:\n",
    "    conn.close()\n",
    "    print('Database connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e52d6-fb39-4c24-8313-876c91cfbfd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import data from each worksheet\n",
    "\n",
    "In the following section, I proceed to iterate through worksheets in the the workbook, using functions defined in the `fireveg` and `firevegdb` modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a8587-39a6-4b35-ace3-2d3fd12b6c77",
   "metadata": {},
   "source": [
    "Here is the list of available worksheets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06059945-d0ff-48d9-a1db-9879fc6f8b32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SiteData', 'FireEvents', 'PlantCounts'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbindex[filename].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ba7a9-37a2-421b-af9f-6e71cc3aec11",
   "metadata": {},
   "source": [
    "If we select one workbook, we can retrieve a list of column names that we will use in our column definitions for each function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5650fbaf-cdf8-4f8d-b602-9c6b9e5456ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Site_subplot_census\n",
      "1 :: Site\n",
      "2 :: Subplot\n",
      "3 :: Replicate\n",
      "4 :: Observers (comma sep if >1)\n",
      "5 :: Date of samping\n",
      "6 :: Survey Date Replicate 1\n",
      "7 :: Survey Date Replicate 2\n",
      "8 :: Survey Date Replicate 3\n",
      "9 :: Survey Date Replicate 4\n",
      "10 :: Survey Date Replicate 5\n",
      "11 :: Survey Date Replicate 6\n",
      "12 :: Location text\n",
      "13 :: Zone\n",
      "14 :: Easting\n",
      "15 :: Northing\n",
      "16 :: GPS Precision (m)\n",
      "17 :: Latitude\n",
      "18 :: Longitude\n",
      "19 :: Layout & GPS marker position\n",
      "20 :: 2nd ref point Zone\n",
      "21 :: 2nd ref point Easting\n",
      "22 :: 2nd ref point Northing\n",
      "23 :: 2nd ref point Position of GPS\n",
      "24 :: 3rd ref point Zone\n",
      "25 :: 3rd ref point Easting\n",
      "26 :: 3rd ref point Northing\n",
      "27 :: 3rd ref point Position of GPS\n",
      "28 :: 4th ref point Zone\n",
      "29 :: 4th ref point Easting\n",
      "30 :: 4th ref point Northing\n",
      "31 :: 4th ref point Position of GPS\n",
      "32 :: Total sample area (sq.m)\n",
      "33 :: Subquadrat area (sq.m)\n",
      "34 :: # subquadrats\n",
      "35 :: Substrate\n",
      "36 :: Notes\n",
      "37 :: Slope\n",
      "38 :: Aspect\n",
      "39 :: Elevation\n",
      "40 :: Disturbance notes\n",
      "41 :: Cwth TEC\n",
      "42 :: NSW TEC\n",
      "43 :: variant\n",
      "44 :: Vegetation formation\n",
      "45 :: Vegegtation class\n"
     ]
    }
   ],
   "source": [
    "cols=wbindex[filename]['SiteData']\n",
    "for k in range(1,len(cols)):\n",
    "    print(\"%s :: %s\" % (k-1,cols[k-1]))\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c820990-1773-499e-98d7-c841259d5dfd",
   "metadata": {},
   "source": [
    "### Import site visits records into database\n",
    "\n",
    "- 56 sites/visits in the period 2011 to 2018\n",
    "- But we need to fix the site label to exclude the replicate number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abf3fdb8-4ae7-4390-8e12-fdade4fecf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict = {'site_label':1,'location_description':12, 'utm_zone':13,'xs':(14,), 'ys':(15,), \n",
    "        'gps_geom_description':19, \n",
    "         'visit_date':(5,), 'replicate_nr':3,'observerlist':4, 'survey':\"Mallee Woodlands\"}\n",
    "\n",
    "site_records = fv.import_records_from_workbook(filepath=inputdir,\n",
    "                                               workbook='PlantFireTraitData_2011-2018_Import.xlsx',\n",
    "                                                worksheet='SiteData',\n",
    "                                                col_dictionary=cdict,\n",
    "                                                create_record_function=fv.create_field_site_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eec094b2-e2e3-4715-af5e-12fba2e52969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site_label': 'S2007/2',\n",
       " 'location_description': 'Scotia Sanctuary, southwestern sector, West of Elliots Bore, edge of burnt area',\n",
       " 'gps_geom_description': 'Centre point at intersection of A, K, R & N subplots with G subplot adjacent and X1-X3 separated and wrapped around G subplot',\n",
       " 'geom': \"ST_GeomFromText('POINT(505169 6318145)', 28354)\"}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_records[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "204f1388-08a5-43ba-ae38-65358e657a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "56 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.field_site\",site_records,keycol=('site_label',), idx='field_site_pkey1',execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d114377-13c0-4333-982c-9e6829b7447c",
   "metadata": {},
   "source": [
    "insert location and visit records based on the sample id, but then, how do we transform the subploots into sample nrs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b69cf3f-f0ed-434d-946d-05c7e6488cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_records = fv.import_records_from_workbook(filepath=inputdir,\n",
    "                                          workbook='PlantFireTraitData_2011-2018_Import.xlsx',\n",
    "                                            worksheet='SiteData',\n",
    "                                            col_dictionary=cdict,\n",
    "                                            create_record_function=fv.create_field_visit_record) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8929717-71be-4c63-8947-69696bc5d74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2007/2',\n",
       " 'visit_date': datetime.datetime(2013, 9, 24, 0, 0),\n",
       " 'survey_name': 'Mallee Woodlands',\n",
       " 'observerlist': ['David Keith'],\n",
       " 'replicate_nr': 3}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_records[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f227615-f291-4060-aff0-10fc89ea4989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "53 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.field_visit\",visit_records,keycol=('visit_id','visit_date'), idx='field_visit_pkey2',execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b360c-794e-42f7-ac0c-11902d42132f",
   "metadata": {},
   "source": [
    "### Import fire history records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5a9f2-fe0a-4a32-a2b7-e3129ecc44bc",
   "metadata": {},
   "source": [
    "This was provided by David in May 2023, check if it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b93a5afc-c4cb-47cd-bf9e-e25a55dbd9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Site\n",
      "1 :: Replicate\n",
      "2 :: Date of last fire dd/mm/yyyy\n",
      "3 :: Date of penultimate fire\n",
      "4 :: Date of earlier fire\n",
      "5 :: How date inferred1\n",
      "6 :: How date inferred2\n",
      "7 :: How date inferred3\n",
      "8 :: Ignition cause1\n",
      "9 :: Ignition cause2\n",
      "10 :: Ignition cause3\n",
      "11 :: Scorch hgt (m) min\n",
      "12 :: Scorch hgt (m) mas\n",
      "13 :: Scorch hgt (m) mode\n",
      "14 :: % Tree foliage scorch\n",
      "15 :: % Tree foliage c'sume\n",
      "16 :: % Shb foliage scorch\n",
      "17 :: % Shb foliage c'sume\n",
      "18 :: % Herb layer foliage scorch\n",
      "19 :: % Herb layer foliage c'sume\n",
      "20 :: Twig diam (mm) 1\n",
      "21 :: Twig diam (mm) 2\n",
      "22 :: Twig diam (mm) 3\n",
      "23 :: Twig diam (mm) 4\n",
      "24 :: Twig diam (mm) 5\n",
      "25 :: Twig diam (mm) 6\n",
      "26 :: Twig diam (mm) 7\n",
      "27 :: Twig diam (mm) 8\n",
      "28 :: Twig diam (mm) 9\n",
      "29 :: Twig diam (mm) 10\n",
      "30 :: Peat depth burnt (cm)\n",
      "31 :: Peat extent burnt %quad\n"
     ]
    }
   ],
   "source": [
    "worksheet = 'FireEvents'\n",
    "#wbindex[filename][worksheet][0][0:13]\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols)):\n",
    "    print(\"%s :: %s\" % (k-1,cols[k-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5f9f4f3-7a77-4135-8224-6d8aa9865a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dicts=[{'site_label':0,'fire_date':2,'how_inferred':5,'cause_of_ignition':8},\n",
    "    {'site_label':0,'fire_date':3,'how_inferred':6,'cause_of_ignition':9},\n",
    "    {'site_label':0,'fire_date':4,'how_inferred':7,'cause_of_ignition':10}]\n",
    "fire_records = fv.import_records_from_workbook(inputdir, filename, worksheet, col_dicts, create_record_function=fv.create_fire_history_record)\n",
    "len(fire_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bce37286-130b-4e69-986c-301692f70b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site_label': 'S2007/1_X1_3',\n",
       " 'fire_date': '2006-11-01',\n",
       " 'earliest_date': datetime.date(2006, 11, 1),\n",
       " 'latest_date': datetime.date(2006, 11, 1),\n",
       " 'how_inferred': 'Land manager records & pers obs'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_records[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c438a0-1853-471e-a364-542f6c0185c1",
   "metadata": {},
   "source": [
    "Need to adjust the site label (remove the trailing replicate number, and include all the missing site labels (sites with fire history but no visit recorded yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e35c82-3686-4aa2-b88f-2ef829661ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = list()\n",
    "for record in fire_records:\n",
    "    record['site_label']=re.sub(\"_[0-9]$\",\"\",record['site_label'])\n",
    "    all_sites.append(record['site_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7ca9a17-3e1e-4133-8298-e02bd4322670",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_site_records=list()\n",
    "all_sites = set(all_sites)\n",
    "\n",
    "for site in all_sites:\n",
    "    add_site_records.append({'site_label':site})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c79c7bc-f164-41be-8985-3d75ea589d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add_site_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ae7017a-5e91-4a66-a554-61dab02dbe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'site_label': 'S2011/3_G'},\n",
       " {'site_label': 'T2017/4_NX'},\n",
       " {'site_label': 'S2011/3_X1'},\n",
       " {'site_label': 'T2000/4_R'},\n",
       " {'site_label': 'T2000/4_X1'},\n",
       " {'site_label': 'T2003/2_G'},\n",
       " {'site_label': 'T2000/1_G'},\n",
       " {'site_label': 'T2006/4_X1'},\n",
       " {'site_label': 'T2001/3_A'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_site_records[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71e6930d-e858-401b-b209-8944f423b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "0 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.field_site\",add_site_records,keycol=(), idx=None,execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9fd93-d1b4-41a5-9d4d-f116910cab8f",
   "metadata": {},
   "source": [
    "Now we can do the batch upsert of all the fire history records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12924461-2533-4635-a8ae-7b44be2ce521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "639 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.fire_history\",fire_records,keycol=('site_label','fire_date'), idx='fire_history_pkey1',execute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3167c4-f8c2-452e-9116-44a227ff40b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3483ba-78ae-4c04-9abe-7c5cf5f96290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1dcdbe3-34cb-4af6-b97f-fbbe1c28b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in site_records:\n",
    "    record['site_label']=re.sub(\"_[AKRNGX123]+_[0-9]$\",\"\",record['site_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30abf65d-9c4c-42a2-aac2-1aa736696158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T2000/3_K'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_records[22]['site_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "756997fa-ad81-4e91-8775-91dfef587b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2007/1_A_3',\n",
       " 'visit_date': datetime.datetime(2011, 10, 28, 0, 0),\n",
       " 'survey_name': 'Mallee Woodlands',\n",
       " 'observerlist': ['Mark Tozer'],\n",
       " 'replicate_nr': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9abaa665-0a05-40ae-a376-fdc465bfbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in visit_records:\n",
    "    record['visit_id']=re.sub(\"_[0-9]$\",\"\",record['visit_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5480595-a356-4738-81d7-c3b7298879ac",
   "metadata": {},
   "source": [
    "### Import plant count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a72ccac-4c15-4d56-a802-223555623ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: site_subplot_cen\n",
      "1 :: Species_name\n",
      "2 :: Recovery organ\n",
      "3 :: Seedbank\n",
      "4 :: Count of unburnt adlt individuals\n",
      "5 :: Count of unburnt juv individuals\n",
      "6 :: Count of resprouting juv individuals.\n",
      "7 :: Count of resprouting adult individuals.\n",
      "8 ::  # resprouted & died post-fire\n",
      "9 :: Count of fire-killed juv individuals\n",
      "10 :: Count of fire-killed adult individuals\n",
      "11 :: #  reproductive pre-fire plants\n",
      "12 :: Count of live postfire recruits\n",
      "13 :: #  reproductive post-fire recruits\n",
      "14 :: # recruits died post-fire\n",
      "15 :: # reproductive recruits died post-fire\n",
      "16 :: # live interfire recruits (>3yr postfire emerg\n",
      "17 :: # live reproductive interfire recruits (>3yr postfire emerg\n",
      "18 :: # deadinterfire recruits (>3yr postfire emerg)\n"
     ]
    }
   ],
   "source": [
    "worksheet = 'PlantCounts'\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols)):\n",
    "    print(\"%s :: %s\" % (k-1,cols[k-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9baef3-11c6-49e2-8f39-e98d80da248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict={'visit_id':0, 'species':1,   \n",
    "          'resprout_organ':2, 'seedbank':3,\n",
    "          'adults_unburnt':4,\n",
    "          'resprouts_live':6,\n",
    "          'resprouts_kill':8,\n",
    "          'resprouts_reproductive':7,\n",
    "          'recruits_live':12, \n",
    "          'recruits_died':14, \n",
    "          'recruits_reproductive':13,\n",
    "          'notes':19,'workbook':filename,'worksheet':worksheet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e82484ca-956a-4e96-bc8d-8bdab816858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrats = fv.import_records_from_workbook(inputdir, filename, worksheet, col_dict,\n",
    "                                       fv.create_field_sample_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37543ed2-1920-4b43-b03d-6bb476881322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9051"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quadrats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db95b956-047b-43b5-92f4-7cfa881d55a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2007/6_X1_3', 'replicate_nr': None, 'sample_nr': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadrats[555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8323dedd-1b6f-4517-902d-e23e5e28017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in quadrats:\n",
    "    record['replicate_nr']=re.findall(r'\\d+$', quadrats[555]['visit_id'])[0]\n",
    "    record['sample_nr']=1\n",
    "    record['visit_id']=re.sub(\"_[0-9]$\",\"\",record['visit_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02c269f2-2bd5-4f4b-9ca0-b682cc5d808b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2007/6_X1', 'replicate_nr': '3', 'sample_nr': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadrats[555]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53272920-27b1-4099-8157-7706f5414791",
   "metadata": {},
   "source": [
    "Now check which ones are valid visit records (already present in the database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3404e0e-65a4-4c13-8de9-03d50fbda901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K250_ not found\n",
      "K251_ not found\n",
      "K253_ not found\n",
      "K254_ not found\n",
      "K258_ not found\n",
      "K259_ not found\n",
      "K260_ not found\n",
      "K261_ not found\n",
      "K265_ not found\n",
      "K266_ not found\n",
      "K267_ not found\n",
      "K268_ not found\n",
      "S2007/1_X1 not found\n",
      "S2007/1_X2 not found\n",
      "S2007/1_X3 not found\n",
      "record for S2007/2_A is incomplete\n",
      "S2007/2_G not found\n",
      "S2007/2_K not found\n",
      "S2007/2_N not found\n",
      "S2007/2_R not found\n",
      "S2007/2_X1 not found\n",
      "S2007/2_X2 not found\n",
      "record for S2007/3_A is incomplete\n",
      "S2007/3_G not found\n",
      "S2007/3_K not found\n",
      "S2007/3_N not found\n",
      "S2007/3_R not found\n",
      "S2007/3_X1 not found\n",
      "S2007/3_X2 not found\n",
      "S2007/3_X3 not found\n",
      "S2007/4_X1 not found\n",
      "S2007/4_X2 not found\n",
      "S2007/4_X3 not found\n",
      "record for S2007/5_A is incomplete\n",
      "S2007/5_G not found\n",
      "S2007/5_K not found\n",
      "S2007/5_N not found\n",
      "S2007/5_R not found\n",
      "S2007/5_X1 not found\n",
      "S2007/5_X2 not found\n",
      "S2007/5_X3 not found\n",
      "record for S2007/6_A is incomplete\n",
      "S2007/6_G not found\n",
      "S2007/6_K not found\n",
      "S2007/6_N not found\n",
      "S2007/6_R not found\n",
      "S2007/6_X1 not found\n",
      "S2007/6_X2 not found\n",
      "S2007/6_X3 not found\n",
      "record for S2007/7_A is incomplete\n",
      "S2007/7_G not found\n",
      "S2007/7_K not found\n",
      "S2007/7_N not found\n",
      "S2007/7_R not found\n",
      "S2007/7_X1 not found\n",
      "S2007/7_X2 not found\n",
      "S2007/7_X3 not found\n",
      "S2007/8_X1 not found\n",
      "S2007/8_X2 not found\n",
      "S2007/8_X3 not found\n",
      "S2010/1_A not found\n",
      "S2010/1_G not found\n",
      "record for S2010/1_K is incomplete\n",
      "S2010/1_N not found\n",
      "S2010/1_R not found\n",
      "record for S2010/2_A is incomplete\n",
      "S2010/2_G not found\n",
      "S2010/2_K not found\n",
      "S2010/2_N not found\n",
      "S2010/2_R not found\n",
      "record for S2010/3_A is incomplete\n",
      "S2010/3_G not found\n",
      "S2010/3_K not found\n",
      "S2010/3_N not found\n",
      "S2010/3_R not found\n",
      "S2010/4_A not found\n",
      "S2010/4_G not found\n",
      "record for S2010/4_K is incomplete\n",
      "S2010/4_N not found\n",
      "S2010/4_R not found\n",
      "S2011/1_A not found\n",
      "S2011/1_G not found\n",
      "S2011/1_K not found\n",
      "S2011/1_N not found\n",
      "S2011/1_R not found\n",
      "S2011/1_X1 not found\n",
      "S2011/1_X2 not found\n",
      "S2011/1_X3 not found\n",
      "record for S2011/3_A is incomplete\n",
      "S2011/3_G not found\n",
      "S2011/3_K not found\n",
      "S2011/3_N not found\n",
      "S2011/3_R not found\n",
      "record for S2012/1_A is incomplete\n",
      "S2012/1_G not found\n",
      "S2012/1_K not found\n",
      "S2012/1_N not found\n",
      "S2012/1_R not found\n",
      "S2012/1_X1 not found\n",
      "S2012/1_X2 not found\n",
      "S2012/1_X3 not found\n",
      "record for S2012/2_A is incomplete\n",
      "S2012/2_G not found\n",
      "S2012/2_K not found\n",
      "S2012/2_N not found\n",
      "S2012/2_R not found\n",
      "S2012/2_X1 not found\n",
      "S2012/2_X2 not found\n",
      "S2012/2_X3 not found\n",
      "record for S2012/4_A is incomplete\n",
      "S2012/4_G not found\n",
      "S2012/4_K not found\n",
      "S2012/4_N not found\n",
      "S2012/4_R not found\n",
      "S2012/4_X1 not found\n",
      "S2012/4_X2 not found\n",
      "S2012/4_X3 not found\n",
      "record for S2012/6_A is incomplete\n",
      "S2012/6_G not found\n",
      "S2012/6_K not found\n",
      "S2012/6_N not found\n",
      "S2012/6_R not found\n",
      "S2012/6_X1 not found\n",
      "S2012/6_X2 not found\n",
      "S2012/6_X3 not found\n",
      "record for S2012/7_A is incomplete\n",
      "S2012/7_G not found\n",
      "S2012/7_K not found\n",
      "S2012/7_N not found\n",
      "S2012/7_R not found\n",
      "S2012/7_X1 not found\n",
      "S2012/7_X2 not found\n",
      "S2012/7_X3 not found\n",
      "record for T1997/1_A is incomplete\n",
      "T1997/1_K not found\n",
      "T1997/1_N not found\n",
      "T1997/1_R not found\n",
      "record for T1997/2_A is incomplete\n",
      "T1997/2_K not found\n",
      "T1997/2_N not found\n",
      "T1997/2_R not found\n",
      "T1998/CON1_A_ not found\n",
      "T1998/CON1_K_ not found\n",
      "T1998/CON1_N_ not found\n",
      "T1998/CON1_R_ not found\n",
      "T2000/1_A not found\n",
      "T2000/1_G not found\n",
      "record for T2000/1_K is incomplete\n",
      "T2000/1_N not found\n",
      "T2000/1_R not found\n",
      "T2000/1_X1 not found\n",
      "T2000/1_X2 not found\n",
      "T2000/1_X3 not found\n",
      "T2000/2_A not found\n",
      "T2000/2_G not found\n",
      "record for T2000/2_K is incomplete\n",
      "T2000/2_N not found\n",
      "T2000/2_R not found\n",
      "T2000/2_X1 not found\n",
      "T2000/2_X2 not found\n",
      "T2000/2_X3 not found\n",
      "T2000/3_X1 not found\n",
      "T2000/3_X2 not found\n",
      "T2000/3_X3 not found\n",
      "record for T2000/4_A is incomplete\n",
      "T2000/4_G not found\n",
      "T2000/4_K not found\n",
      "T2000/4_N not found\n",
      "T2000/4_R not found\n",
      "T2000/4_X1 not found\n",
      "T2000/4_X2 not found\n",
      "T2000/4_X3 not found\n",
      "record for T2001/1_A is incomplete\n",
      "T2001/1_G not found\n",
      "T2001/1_K not found\n",
      "T2001/1_N not found\n",
      "T2001/1_R not found\n",
      "T2001/1_X1 not found\n",
      "T2001/1_X2 not found\n",
      "T2001/1_X3 not found\n",
      "T2001/2_X1 not found\n",
      "T2001/2_X2 not found\n",
      "T2001/2_X3 not found\n",
      "record for T2001/3_A is incomplete\n",
      "T2001/3_G not found\n",
      "T2001/3_K not found\n",
      "T2001/3_N not found\n",
      "T2001/3_R not found\n",
      "T2001/3_X1 not found\n",
      "T2001/3_X2 not found\n",
      "T2001/3_X3 not found\n",
      "record for T2001/4_A is incomplete\n",
      "T2001/4_G not found\n",
      "T2001/4_K not found\n",
      "T2001/4_N not found\n",
      "T2001/4_R not found\n",
      "T2001/4_X1 not found\n",
      "T2001/4_X2 not found\n",
      "T2001/4_X3 not found\n",
      "T2003/1_A not found\n",
      "T2003/1_G not found\n",
      "record for T2003/1_K is incomplete\n",
      "T2003/1_N not found\n",
      "T2003/1_R not found\n",
      "T2003/1_X1 not found\n",
      "T2003/1_X2 not found\n",
      "T2003/1_X3 not found\n",
      "T2003/2_X1 not found\n",
      "T2003/2_X2 not found\n",
      "T2003/2_X3 not found\n",
      "T2003/3_A not found\n",
      "T2003/3_G not found\n",
      "T2003/3_K not found\n",
      "T2003/3_N not found\n",
      "T2003/3_R not found\n",
      "T2003/3_X1 not found\n",
      "T2003/3_X2 not found\n",
      "T2003/3_X3 not found\n",
      "record for T2003/4_A is incomplete\n",
      "T2003/4_G not found\n",
      "T2003/4_K not found\n",
      "T2003/4_N not found\n",
      "T2003/4_R not found\n",
      "T2003/4_X1 not found\n",
      "T2003/4_X2 not found\n",
      "T2003/4_X3 not found\n",
      "record for T2005/1_A is incomplete\n",
      "T2005/1_G not found\n",
      "T2005/1_K not found\n",
      "T2005/1_N not found\n",
      "T2005/1_R not found\n",
      "T2005/1_X1 not found\n",
      "T2005/1_X2 not found\n",
      "T2005/1_X3 not found\n",
      "record for T2005/2_A is incomplete\n",
      "T2005/2_G not found\n",
      "T2005/2_K not found\n",
      "T2005/2_N not found\n",
      "T2005/2_R not found\n",
      "T2005/2_X1 not found\n",
      "T2005/2_X2 not found\n",
      "T2005/2_X3 not found\n",
      "record for T2005/3_A is incomplete\n",
      "T2005/3_G not found\n",
      "T2005/3_K not found\n",
      "T2005/3_N not found\n",
      "T2005/3_R not found\n",
      "T2005/3_X1 not found\n",
      "T2005/3_X2 not found\n",
      "T2005/3_X3 not found\n",
      "record for T2005/4_A is incomplete\n",
      "T2005/4_G not found\n",
      "T2005/4_K not found\n",
      "T2005/4_N not found\n",
      "T2005/4_R not found\n",
      "T2005/4_X1 not found\n",
      "T2005/4_X2 not found\n",
      "T2005/4_X3 not found\n",
      "record for T2005/5_A is incomplete\n",
      "T2005/5_G not found\n",
      "T2005/5_K not found\n",
      "T2005/5_N not found\n",
      "T2005/5_R not found\n",
      "T2005/5_X1 not found\n",
      "T2005/5_X2 not found\n",
      "T2005/5_X3 not found\n",
      "record for T2006/1_A is incomplete\n",
      "T2006/1_G not found\n",
      "T2006/1_K not found\n",
      "T2006/1_N not found\n",
      "T2006/1_R not found\n",
      "T2006/1_X1 not found\n",
      "T2006/1_X2 not found\n",
      "T2006/1_X3 not found\n",
      "record for T2006/2_A is incomplete\n",
      "T2006/2_G not found\n",
      "T2006/2_K not found\n",
      "T2006/2_N not found\n",
      "T2006/2_R not found\n",
      "T2006/2_X1 not found\n",
      "T2006/2_X2 not found\n",
      "T2006/2_X3 not found\n",
      "record for T2006/3_A is incomplete\n",
      "T2006/3_G not found\n",
      "T2006/3_K not found\n",
      "T2006/3_N not found\n",
      "T2006/3_R not found\n",
      "T2006/3_X1 not found\n",
      "T2006/3_X2 not found\n",
      "T2006/3_X3 not found\n",
      "record for T2006/4_A is incomplete\n",
      "T2006/4_G not found\n",
      "T2006/4_K not found\n",
      "T2006/4_N not found\n",
      "T2006/4_R not found\n",
      "T2006/4_X1 not found\n",
      "T2006/4_X2 not found\n",
      "T2006/4_X3 not found\n",
      "record for T2011/1_A is incomplete\n",
      "T2011/1_G not found\n",
      "T2011/1_K not found\n",
      "T2011/1_N not found\n",
      "T2011/1_R not found\n",
      "T2011/1_X1 not found\n",
      "T2011/1_X2 not found\n",
      "T2011/1_X3 not found\n",
      "record for T2011/2_A is incomplete\n",
      "T2011/2_G not found\n",
      "T2011/2_K not found\n",
      "T2011/2_N not found\n",
      "T2011/2_R not found\n",
      "T2011/2_X1 not found\n",
      "T2011/2_X2 not found\n",
      "T2011/2_X3 not found\n",
      "record for T2011/3_A is incomplete\n",
      "T2011/3_G not found\n",
      "T2011/3_K not found\n",
      "T2011/3_N not found\n",
      "T2011/3_R not found\n",
      "T2011/3_X1 not found\n",
      "T2011/3_X2 not found\n",
      "T2011/3_X3 not found\n",
      "record for T2011/4_A is incomplete\n",
      "T2011/4_G not found\n",
      "T2011/4_K not found\n",
      "T2011/4_N not found\n",
      "T2011/4_R not found\n",
      "T2011/4_X1 not found\n",
      "T2011/4_X2 not found\n",
      "T2011/4_X3 not found\n",
      "record for T2017/1_A is incomplete\n",
      "T2017/1_AX not found\n",
      "T2017/1_K not found\n",
      "T2017/1_KX not found\n",
      "T2017/1_N not found\n",
      "T2017/1_NX not found\n",
      "T2017/1_R not found\n",
      "T2017/1_RX not found\n",
      "record for T2017/2_A is incomplete\n",
      "record for T2017/2_AX is incomplete\n",
      "T2017/2_K not found\n",
      "T2017/2_KX not found\n",
      "T2017/2_N not found\n",
      "T2017/2_NX not found\n",
      "T2017/2_R not found\n",
      "T2017/2_RX not found\n",
      "record for T2017/3_A is incomplete\n",
      "record for T2017/3_AX is incomplete\n",
      "T2017/3_K not found\n",
      "T2017/3_KX not found\n",
      "T2017/3_N not found\n",
      "T2017/3_NX not found\n",
      "T2017/3_R not found\n",
      "T2017/3_RX not found\n",
      "record for T2017/4_A is incomplete\n",
      "record for T2017/4_AX is incomplete\n",
      "T2017/4_K not found\n",
      "T2017/4_KX not found\n",
      "T2017/4_N not found\n",
      "T2017/4_NX not found\n",
      "T2017/4_R not found\n",
      "T2017/4_RX not found\n",
      "record for T2017/5_A is incomplete\n",
      "T2017/5_AX not found\n",
      "T2017/5_K not found\n",
      "T2017/5_KX not found\n",
      "T2017/5_N not found\n",
      "T2017/5_NX not found\n",
      "T2017/5_R not found\n",
      "T2017/5_RX not found\n",
      "0 rows updated\n"
     ]
    }
   ],
   "source": [
    "new_conn = psycopg2.connect(**dbparams)\n",
    "valid_visits = validate_and_update_site_records(quadrats,useconn=new_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "681922ef-e2e4-4c5e-b206-a767c32fdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a21b6e5a-77ed-47b3-858e-04b45e97df27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_visits)\n",
    "#len(quadrats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56ed6149-c73c-4a12-80a4-5be9f0cfae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quadrat_sample_record(item,sw,lookup,valid_seedbank,valid_organ):\n",
    "    species = item[sw['species']].value\n",
    "    visit_id =  item[sw['visit_id']].value\n",
    "    if 'sample_nr' in sw.keys():\n",
    "        sample_nr=item[sw['sample_nr']].value\n",
    "    else:\n",
    "        sample_nr=1\n",
    "    if species is not None:\n",
    "        record={'visit_id': visit_id, 'sample_nr': sample_nr,\n",
    "                'species': species}\n",
    "        comms=list()\n",
    "        if 'workbook' in sw.keys():\n",
    "            comms.append(\"Imported from workbook %s using python script\" % sw['workbook'])\n",
    "        if 'worksheet' in sw.keys():\n",
    "            comms.append(\"Imported from spreadsheet %s\" % sw['worksheet'])\n",
    "    \n",
    "        if 'date' in sw.keys():\n",
    "            visit_date = item[sw['date']].value\n",
    "        else:\n",
    "            visit_date = None\n",
    "            \n",
    "        if 'replicate_nr' in sw.keys():\n",
    "            replicate_nr = item[sw['replicate_nr']].value\n",
    "        elif 'fixed_replicate_nr' in sw.keys():\n",
    "            replicate_nr = sw['fixed_replicate_nr']\n",
    "        \n",
    "        if isinstance(visit_date,datetime):\n",
    "            record['visit_date'] = visit_date.date()\n",
    "        else:    \n",
    "            p=filter(lambda n: n['visit_id'] == visit_id and  n['replicate_nr'] == replicate_nr, lookup)\n",
    "            found=list(p)\n",
    "            if len(found)==1 and 'visit_date' in found[0].keys():\n",
    "                visit_date=found[0]['visit_date']\n",
    "                if isinstance(visit_date,datetime):\n",
    "                    record['visit_date'] = visit_date.date()\n",
    "                    comms.append(\"visit date not provided, matched by replicate nr %s\" % replicate_nr)\n",
    "                else:\n",
    "                    record['visit_date'] = visit_date\n",
    "                    comms.append(\"matched by replicate nr %s, assuming date object\" % replicate_nr)\n",
    "            else:\n",
    "                comms.append(\"neither visit date nor replicate nr was matched ( replicate nr %s ), no date\" % replicate_nr)\n",
    "\n",
    "        if 'spcode' in sw.keys():\n",
    "            spcode = item[sw['spcode']].value\n",
    "            if (isinstance(spcode, str) and spcode.isnumeric()) or isinstance(spcode,int):\n",
    "                record['species_code']=spcode\n",
    "         \n",
    "        for k in ('species_notes', 'resprout_organ', 'seedbank', 'adults_unburnt', 'resprouts_live', 'resprouts_died', 'resprouts_kill', 'resprouts_reproductive',\n",
    "                  'recruits_live', 'recruits_reproductive', 'recruits_died','notes'):\n",
    "            if k in sw.keys():\n",
    "                vals=item[sw[k]].value\n",
    "                if vals is not None and vals not in ('na','NA'):\n",
    "                    if k == 'resprout_organ':\n",
    "                        if vals in valid_organ:\n",
    "                            record[k]=vals\n",
    "                        elif vals.capitalize() in valid_organ:\n",
    "                            record[k]=vals.capitalize()\n",
    "                        else:\n",
    "                            comms.append(\"resprout organ written as %s\" % vals)\n",
    "                    elif k == 'seedbank':\n",
    "                        if vals in valid_seedbank:\n",
    "                            record[k]=vals\n",
    "                        elif vals.capitalize() in valid_seedbank:\n",
    "                            record[k]=vals.capitalize()\n",
    "                        else:\n",
    "                            comms.append(\"seedbank written as %s\" % vals)\n",
    "                    elif k == 'notes':\n",
    "                        if isinstance(vals,(int, float, complex)):\n",
    "                            comms.append(\"Comment column included a numeric value of %s\" % vals)\n",
    "                        else:\n",
    "                            comms.append(vals)\n",
    "                    elif k in ('adults_unburnt', 'resprouts_live', 'resprouts_died', 'resprouts_kill', 'resprouts_reproductive',\n",
    "                  'recruits_live', 'recruits_reproductive', 'recruits_died'):\n",
    "                        if isinstance(vals,int):\n",
    "                            record[k]=vals   \n",
    "                        else:\n",
    "                            comms.append(\"%s written as %s\" % (k,vals))\n",
    "                    else:\n",
    "                        record[k]=vals        \n",
    "        \n",
    "        if len(comms)>0:\n",
    "            record[\"comments\"]=comms\n",
    "        \n",
    "        return(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "409d0493-cca5-4f2b-89b3-481b1cd2028a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'replicate_nr' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m records\u001b[38;5;241m=\u001b[39m\u001b[43mfv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_records_from_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworksheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mcreate_quadrat_sample_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mlookup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_visits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mvalid_seedbank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseedbank_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mvalid_organ\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morgan_vocab\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proyectos/fireveg/fire-veg-aust/lib/fireveg.py:243\u001b[0m, in \u001b[0;36mimport_records_from_workbook\u001b[0;34m(filepath, workbook, worksheet, col_dictionary, create_record_function, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,row_count):\n\u001b[1;32m    242\u001b[0m     item\u001b[38;5;241m=\u001b[39mws[k]\n\u001b[0;32m--> 243\u001b[0m     record\u001b[38;5;241m=\u001b[39m\u001b[43mcreate_record_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcol_dictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(record)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlist\u001b[39m:\n",
      "Cell \u001b[0;32mIn[27], line 41\u001b[0m, in \u001b[0;36mcreate_quadrat_sample_record\u001b[0;34m(item, sw, lookup, valid_seedbank, valid_organ)\u001b[0m\n\u001b[1;32m     39\u001b[0m             comms\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatched by replicate nr \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, assuming date object\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m replicate_nr)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m         comms\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneither visit date nor replicate nr was matched ( replicate nr \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m ), no date\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[43mreplicate_nr\u001b[49m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspcode\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sw\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     44\u001b[0m     spcode \u001b[38;5;241m=\u001b[39m item[sw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspcode\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'replicate_nr' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "records=fv.import_records_from_workbook(inputdir, filename, worksheet, col_dict,\n",
    "                                         create_quadrat_sample_record,\n",
    "                                         lookup=valid_visits, \n",
    "                                        valid_seedbank=seedbank_vocab, \n",
    "                                        valid_organ=organ_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66640f4b-804e-4729-91bb-cf464bfc2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    \n",
    "        valid_records=list()\n",
    "    invalid_records=list()\n",
    "    for record in records:\n",
    "        if 'replicate_nr' in record.keys():\n",
    "            replicate_nr = record['replicate_nr']\n",
    "        elif 'fixed_replicate_nr' in record.keys():\n",
    "            replicate_nr = col_dictionary['fixed_replicate_nr']\n",
    "        else:\n",
    "            replicate_nr = None\n",
    "        \n",
    "        if 'visit_date' in record.keys():\n",
    "            p=filter(lambda n: n['visit_id'] == record['visit_id'] and  n['visit_date'] == record['visit_date'], valid_visits)\n",
    "            found=list(p)\n",
    "        elif 'replicate_nr' in record.keys():\n",
    "            p=filter(lambda n: n['visit_id'] == record['visit_id'] and  n['replicate_nr'] == replicate_nr, valid_visits)\n",
    "            found=list(p)\n",
    "        else:\n",
    "            found=list()\n",
    "        \n",
    "        if (len(found)==1):\n",
    "            valid_records.append(record)\n",
    "        else:\n",
    "            invalid_records.append(record)\n",
    "\n",
    "    print(\"%s valid records and %s invalid records\" % (len(valid_records), len(invalid_records)))\n",
    "    \n",
    "    batch_upsert(params,table='form.quadrat_samples',records=valid_records,keycol=('visit_id','visit_date','sample_nr'),\n",
    "             idx=None, execute=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
